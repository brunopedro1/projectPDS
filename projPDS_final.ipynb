{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "afcbb20e",
      "metadata": {
        "id": "afcbb20e"
      },
      "source": [
        "# Digital Signal Processing Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d8dde4c",
      "metadata": {
        "id": "8d8dde4c"
      },
      "source": [
        "Instituto Superior Técnico\n",
        "\n",
        "Digital Signal Processing \n",
        "\n",
        "Prof. Luis Caldas de Oliveira\n",
        "\n",
        "April 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5128f051",
      "metadata": {
        "id": "5128f051"
      },
      "source": [
        "## Authors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b40823c8",
      "metadata": {
        "id": "b40823c8"
      },
      "source": [
        "**Group 03**\n",
        "\n",
        "Yandi Jiang, 96344\n",
        "\n",
        "Bruno Pedro, 96363"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fa558ec",
      "metadata": {
        "id": "2fa558ec"
      },
      "source": [
        "## Instructions and Description"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe667966",
      "metadata": {
        "id": "fe667966"
      },
      "source": [
        "This notebook concerns the final version of the project of Digital Signal Processing (DSP) course, at Instituto Superior Técnico, University of Lisbon. Its main objetive is the extraction of features from audio recordings of instruments interpreting musical melodies and its reinterpretation by a digital polyphonic synthesizer. \n",
        "\n",
        "The features to be extracted include the detection of note onsets, the pitch, amplitude and duration of each note and, also, the beat and tempo of the melody. The features extracted are, then, organized and used to synthesize a new audio with a different timbre, representing a new interpretation of the same musical melody. The synthesized audio can be modified in order to represent different instruments, and, also, to change some characteristics of the original melody, such as the beat and tempo, the ADSR (attack, decay, sustain, release) envelope of the sound waveform, the octave of the notes or, finally, the addition of an overlaid delayed sound.\n",
        "\n",
        "The code of this project is organized in three main parts. The first part, which includes the actual code functions developed, is stored outside this Jupyter Notebook, in separated python script files (.py) that are imported here from the GitHub repository (https://github.com/brunopedro1/projectPDS.git) where all the project files are stored. The script feature_extration.py contains all the code necessary to perform the onset detection, including functions to detect the onsets, find the best threshold values and evaluate the performance of the detection, and, also, all the code to perform the extraction of pitch, amplitude and duration of the notes and organize them in a composition. The script file synth.py contains all the code necessary to perform the polyphonic synthesis of an audio from a composition, which includes functions to find the frequency of notes, generate and synthesize wavetables, define a ADSR envelope of the waveform, synthesize audio from a composition according to the chosen wavetable and envolpe, modify the beat, add overlaid delayed sound, and plot the waveform and spectrogram of the audio. \n",
        "\n",
        "The second part is where the developed code is applied to some audio recordings and the performance of the obtained results is assessed. First, concerning the onset detection, the performance of the implemented algorithms is evaluated by comparison with human annotations of the true onsets and the results are presented in tables that show the number of True Positives, False Positives and False Negatives onsets, and Precision, Recall and F-measure values. The avarage F-measure for each onset detection method is, also, computed and the results are shown and commented. Having the best onset detector selected for each audio, the features are, finally, extracted from the audios, namely, the onsets, pitch, amplitude and duration of notes, and beat of the melody. Then, the developed polyphonic synthesizer and audio modification features are applied, in detail, to a specific audio recording of piano ('silhuette.wav')Finally, some final results to demonstrate all the capabilities of the code are presented using different audios of viola and piano. In this case, a qualitative evaluation of the results is done, since it is hard to quantify the performance of synthesized audio. \n",
        "\n",
        "The third part addresses some simple code tests of the main functions developed, namely, the onset detection, extraction of pitch, amplitude and duration of notes and the capacity of polyphony synthesis. For the code tests, some audios with well-known characteristics are used."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video of the Project"
      ],
      "metadata": {
        "id": "H-D8fOuXI6ty"
      },
      "id": "H-D8fOuXI6ty"
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hHfP0OxZERU\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
      ],
      "metadata": {
        "id": "J5gMPZhdI-4_"
      },
      "id": "J5gMPZhdI-4_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "zLiWUL_M9jwm",
      "metadata": {
        "id": "zLiWUL_M9jwm"
      },
      "source": [
        "## Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pYIzLcus1i2i",
      "metadata": {
        "id": "pYIzLcus1i2i"
      },
      "outputs": [],
      "source": [
        "!rm -rf projectPDS\n",
        "!git clone https://github.com/brunopedro1/projectPDS.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MEmXS-8p9jwt",
      "metadata": {
        "id": "MEmXS-8p9jwt"
      },
      "outputs": [],
      "source": [
        "!pip install madmom\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "from IPython.display import Audio\n",
        "from scipy.signal import sawtooth, square\n",
        "\n",
        "# Functions PDS PROJECT: synth.py, feature_extraction.py\n",
        "from projectPDS.synth import synthesizer, plot_audio\n",
        "from projectPDS.feature_extration import find_threshold, onset_analyse_performance\n",
        "from projectPDS.feature_extration import onset_CNN, onset_RNN, onset_complexFlux, onset_superFlux, onset_detection\n",
        "from projectPDS.feature_extration import get_notes, get_amplitude, get_duration, make_composition, get_rms\n",
        "\n",
        "# MADMOM LIBRARY\n",
        "from madmom.features.onsets import CNNOnsetProcessor\n",
        "from madmom.audio.signal import FramedSignal\n",
        "from madmom.features.onsets import RNNOnsetProcessor\n",
        "from madmom.features.onsets import superflux\n",
        "from madmom.features.onsets import complex_flux\n",
        "from madmom.features.onsets import OnsetPeakPickingProcessor\n",
        "from madmom.evaluation.onsets import OnsetEvaluation\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe9e829c",
      "metadata": {
        "id": "fe9e829c"
      },
      "source": [
        "## Load Audio Recordings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49026bf2",
      "metadata": {
        "id": "49026bf2"
      },
      "source": [
        "The audio recordings are stored in a Github repository called \"projectPDS\" that needs to be cloned before running the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8499497f",
      "metadata": {
        "id": "8499497f"
      },
      "outputs": [],
      "source": [
        "audios = ['projectPDS/recordings/minuet.wav', \n",
        "          'projectPDS/recordings/telemann.wav', \n",
        "         'projectPDS/recordings/gurenge.wav',\n",
        "        'projectPDS/recordings/naruto.wav',\n",
        "        'projectPDS/recordings/silhouette.wav'\n",
        "         ]\n",
        "human_onsets =['projectPDS/HumanOnsets/minuet.txt',\n",
        "              'projectPDS/HumanOnsets/telemann.txt',\n",
        "              'projectPDS/HumanOnsets/gurenge.txt',\n",
        "              'projectPDS/HumanOnsets/naruto.txt',\n",
        "              'projectPDS/HumanOnsets/silhouette.txt']\n",
        "          \n",
        "# Load Audio Files\n",
        "s_minuet, fs_minuet = librosa.load('projectPDS/recordings/minuet.wav', sr=48000)\n",
        "s_telemann, fs_telemann = librosa.load('projectPDS/recordings/telemann.wav',sr=48000)\n",
        "s_gurenge, fs_gurenge = librosa.load('projectPDS/recordings/gurenge.wav', sr=48000)\n",
        "s_naruto, fs_naruto = librosa.load('projectPDS/recordings/naruto.wav', sr=48000)\n",
        "s_silhouette, fs_silhouette = librosa.load('projectPDS/recordings/silhouette.wav', sr=48000)\n",
        "#print(color.BOLD + 'Original Audios\\n' + color.END)\n",
        "\n",
        "for audio in audios:\n",
        "    print(audio.rsplit('/',1)[-1])\n",
        "    x, fs = librosa.load(audio) # get audio\n",
        "    display(Audio(data=x, rate=fs));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df32a120",
      "metadata": {
        "id": "df32a120"
      },
      "source": [
        "## Onset Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07bc5d06",
      "metadata": {
        "id": "07bc5d06"
      },
      "source": [
        "Some good onset detection tools from MADMOM library were tried out, such as Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), a method with maximum filter vibrato suppression stage called SuperFlux, a method based on SuperFlux but adds an additional local group delay based tremolo suppression (ComplexFlux). \n",
        "\n",
        "In this part, some important utility functions are used, namely, functions to find the best threshold to use in the onset detectors, to evaluate the onset detection using a Madmom tool, to display the audio recordings and to print the performance results.\n",
        "\n",
        "Five audio recordings (\"minuet.wav\", \"telemann.wav\", \"gurenge.wav\", \"naruto.wav\", \"silhouette.wav\") with repective human onset annotations are tested and the results of the performance evaluation are presented in tables that show the number of True Positives, False Positives and False Negatives onsets, and Precision, Recall and F-measure values. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09329a84",
      "metadata": {
        "id": "09329a84"
      },
      "source": [
        "### Comment about threshold \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ccd5837",
      "metadata": {
        "id": "2ccd5837"
      },
      "source": [
        "The threshold defines the amplitude that identifies the onset. One way to automatically compute the best threshold is to test a range of values and evaluate the F-measure that results when testing the onset detector on an audio recording with human onset annotations for comparison, the find_threshold function is made for this purpose. \n",
        "\n",
        "This function was used to compute the best threshold for each Madmom onset detection method and each recording, but, since only 5 recordings are used here, the resulting values were stored manually, to avoid the unnecessary computation load of finding threshold values that are constant everytime the notebook is executed. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9caf2024",
      "metadata": {
        "id": "9caf2024"
      },
      "outputs": [],
      "source": [
        "#cnn_threshold=find_threshold(audios,CNNOnsetProcessor(),human_onsets, limit=1,fps=100,window_size=0.1)\n",
        "#rnn_threshold=find_threshold(audios,RNNOnsetProcessor(),human_onsets, limit=1,fps=100,window_size=0.1)\n",
        "#superflux_threshold=find_threshold(audios,superflux,human_onsets, limit=10,fps=200,window_size=0.1)\n",
        "#complexflux_threshold=find_threshold(audios,complex_flux,human_onsets,limit=10,fps=200,window_size=0.1)\n",
        "\n",
        "cnn_threshold = [0.55, 0.69, 0.99, 0.99, 0.99]\n",
        "rnn_threshold = [0.38, 0.29, 0.48, 0.49, 0.68]\n",
        "superflux_threshold =[2.8, 2.8, 9.99, 9.99, 9.99]\n",
        "complexflux_threshold=[1.92, 1.92, 8.24, 9.99, 9.99]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ltio0LJTgnp8",
      "metadata": {
        "id": "Ltio0LJTgnp8"
      },
      "source": [
        "### Evaluate Performance of Onset Detectors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nNcVO3Ec-N3I",
      "metadata": {
        "id": "nNcVO3Ec-N3I"
      },
      "source": [
        "CNN Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c591013b",
      "metadata": {
        "id": "c591013b"
      },
      "outputs": [],
      "source": [
        "cnn_performance=onset_analyse_performance(audios, human_onsets,cnn_threshold, onset_CNN , False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dc76cc4",
      "metadata": {
        "id": "0dc76cc4"
      },
      "source": [
        "RNN Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9e68c99",
      "metadata": {
        "id": "c9e68c99"
      },
      "outputs": [],
      "source": [
        "rnn_performance=onset_analyse_performance(audios, human_onsets,rnn_threshold, onset_RNN , False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd12e8a6",
      "metadata": {
        "id": "cd12e8a6"
      },
      "source": [
        "Super Flux Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bdbad27",
      "metadata": {
        "id": "3bdbad27"
      },
      "outputs": [],
      "source": [
        "superflux_performance=onset_analyse_performance(audios, human_onsets,superflux_threshold, onset_superFlux , False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5beb5970",
      "metadata": {
        "id": "5beb5970"
      },
      "source": [
        "Complex Flux Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd13219",
      "metadata": {
        "id": "abd13219"
      },
      "outputs": [],
      "source": [
        "comlexflux_performance=onset_analyse_performance(audios, human_onsets, complexflux_threshold, onset_complexFlux , False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80a90387",
      "metadata": {
        "id": "80a90387"
      },
      "source": [
        "Onset methods Performance Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbea6835",
      "metadata": {
        "id": "dbea6835"
      },
      "outputs": [],
      "source": [
        "perform_results_fmeasure = [['Madmom CNN', cnn_performance],\n",
        "                   ['Madmom RNN', rnn_performance],\n",
        "                   ['Madmom Super Flux',superflux_performance],\n",
        "                    ['Madmom Complex Flux', comlexflux_performance]]\n",
        "\n",
        "print(tabulate(perform_results_fmeasure, headers=['Onset detection method', 'Avarage F-measure']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a202faea",
      "metadata": {
        "id": "a202faea"
      },
      "source": [
        "It is possible to verify, from the previous results, that different onset detection methods give different results for the same audios. Meaning that no method was found that outperformed all the others. However, using the F-measure as the main metric to assess the performance of a method, it can be seen that, in general, the Madmom CNN and RNN are the methods that provide the best results. Both these methods are characterized to use Deep Learning models that are trained with thousands of anootated onsets."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd2af885",
      "metadata": {
        "id": "cd2af885"
      },
      "source": [
        "The best methods to detect onsets for each audio are:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d96554fe",
      "metadata": {
        "id": "d96554fe"
      },
      "source": [
        "| Instrument | Audio | Onset Method | F-measure | threshold \n",
        "| :-: | :---: | :---: | :---: | :-:                          \n",
        "| Viola | Minuet | RNN | 0.94 | 0.38                        \n",
        "| Viola | Telemann | CNN |  1.00 |0.69\n",
        "| Piano | Gurenge | CNN |  1.00 |0.99\n",
        "| Piano | Naruto | CNN |  1.00 |0.99\n",
        "| Piano | Silhouette | CNN |  1.00 |0.99\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d840977",
      "metadata": {
        "id": "5d840977"
      },
      "source": [
        "## Extracting the features from Audio Files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5adc62c5",
      "metadata": {
        "id": "5adc62c5"
      },
      "source": [
        "Now, the same 5 audio recording will be used to show the results of the extraction of onsets, pitch, amplitude and duration of the notes, and beat of the melody."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f43d9479",
      "metadata": {
        "id": "f43d9479"
      },
      "source": [
        "### Onset Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc6e174c",
      "metadata": {
        "id": "fc6e174c"
      },
      "source": [
        "Knowing the best onset detection methods for each audio recording, their onsets are, now, computed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68e7f49c",
      "metadata": {
        "id": "68e7f49c"
      },
      "outputs": [],
      "source": [
        "#Threshold values\n",
        "minuet_threshold = 0.38\n",
        "telemann_threshold = 0.69\n",
        "gurenge_threshold=0.99\n",
        "naruto_threshold=0.99\n",
        "silhouette_threshold = 0.99\n",
        "# Find onsets\n",
        "minuet_onsets=onset_detection('projectPDS/recordings/minuet.wav', RNNOnsetProcessor(),lim=minuet_threshold)\n",
        "telemann_onsets=onset_detection('projectPDS/recordings/telemann.wav', CNNOnsetProcessor(),lim=telemann_threshold)\n",
        "gurenge_onsets=onset_detection('projectPDS/recordings/gurenge.wav', CNNOnsetProcessor(),lim=gurenge_threshold)\n",
        "naruto_onsets=onset_detection('projectPDS/recordings/naruto.wav', CNNOnsetProcessor(),lim=naruto_threshold)\n",
        "silhouette_onsets=onset_detection('projectPDS/recordings/silhouette.wav', CNNOnsetProcessor(),lim=silhouette_threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20190849",
      "metadata": {
        "id": "20190849"
      },
      "source": [
        "### Pitch Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "404fb56d",
      "metadata": {
        "id": "404fb56d"
      },
      "source": [
        "To find the pitch of each note, the autocorrelation method was used in a stationary zone between onsets. Since this stationary zone may fail to detect the correct note, when a false negative onset occurs, for example, a slicing window with a predefined size is used until a correct note is found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81399fbe",
      "metadata": {
        "id": "81399fbe"
      },
      "outputs": [],
      "source": [
        "minuet_notes = get_notes(s_minuet, fs_minuet, minuet_onsets)\n",
        "telemann_notes = get_notes(s_telemann, fs_telemann, telemann_onsets)\n",
        "gurenge_notes = get_notes(s_gurenge, fs_gurenge, gurenge_onsets)\n",
        "naruto_notes = get_notes(s_naruto, fs_naruto, naruto_onsets)\n",
        "silhouette_notes = get_notes(s_silhouette, fs_silhouette, silhouette_onsets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02e7a800",
      "metadata": {
        "id": "02e7a800"
      },
      "source": [
        "### Amplitude Extration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f12c569b",
      "metadata": {
        "id": "f12c569b"
      },
      "source": [
        "The amplitude of the signal is proportional to its RMS value, so the computation of a frame-based RMS is used to detect the amplitude of each note."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0534cf87",
      "metadata": {
        "id": "0534cf87"
      },
      "outputs": [],
      "source": [
        "minuet_amplitude = get_amplitude(s_minuet,fs_minuet, minuet_onsets, 256,32, False)\n",
        "telemann_amplitude = get_amplitude(s_telemann,fs_telemann, telemann_onsets, 256,32, False)\n",
        "gurenge_amplitude = get_amplitude(s_gurenge,fs_gurenge, gurenge_onsets, 256,32, False)\n",
        "naruto_amplitude = get_amplitude(s_naruto,fs_naruto, naruto_onsets, 256,32, False)\n",
        "silhouette_amplitude = get_amplitude(s_silhouette,fs_silhouette, silhouette_onsets, 256,32, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f4329b6",
      "metadata": {
        "id": "2f4329b6"
      },
      "source": [
        "### Duration Extration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a039443c",
      "metadata": {
        "id": "a039443c"
      },
      "source": [
        "In this project, it is assumed that the audios have no pause between notes and the overlap of notes is minimal. So, the duration of a note was defined as the time distance between onsets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b82c9a0",
      "metadata": {
        "id": "3b82c9a0"
      },
      "outputs": [],
      "source": [
        "minuet_duration = get_duration(s_minuet, fs_minuet, minuet_onsets)\n",
        "telemann_duration = get_duration(s_telemann, fs_telemann, telemann_onsets)\n",
        "gurenge_duration = get_duration(s_gurenge, fs_gurenge, gurenge_onsets)\n",
        "naruto_duration = get_duration(s_naruto, fs_naruto, naruto_onsets)\n",
        "silhouette_duration=get_duration(s_silhouette, fs_silhouette, silhouette_onsets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96068ab9",
      "metadata": {
        "id": "96068ab9"
      },
      "source": [
        "### Beat Extration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe90a0c0",
      "metadata": {
        "id": "fe90a0c0"
      },
      "source": [
        "To extract the beat and tempo, a function from Librosa library was directly used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04878da2",
      "metadata": {
        "id": "04878da2"
      },
      "outputs": [],
      "source": [
        "minuet_tempo, _ = librosa.beat.beat_track(y=s_minuet, sr=fs_minuet)\n",
        "telemann_tempo, _ = librosa.beat.beat_track(y=s_telemann, sr=fs_telemann)\n",
        "gurenge_tempo, _ = librosa.beat.beat_track(y=s_gurenge, sr=fs_gurenge)\n",
        "naruto_tempo, _ = librosa.beat.beat_track(y=s_naruto, sr=fs_naruto)\n",
        "silhouette_tempo, _ = librosa.beat.beat_track(y=s_silhouette, sr=fs_silhouette)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8589d27f",
      "metadata": {
        "id": "8589d27f"
      },
      "source": [
        "## Musical Signal Synthesis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "241f11b8",
      "metadata": {
        "id": "241f11b8"
      },
      "source": [
        "Once the features are extracted from the audio and saved in variables. It is possible to organize them in the form of a composition that is used by the polyphonic synthesizer to synthesize a new audio."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09198a40",
      "metadata": {
        "id": "09198a40"
      },
      "source": [
        "### Create composition "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c115b3b",
      "metadata": {
        "id": "9c115b3b"
      },
      "source": [
        "Each note contains [note, amplitude, duration, onset], and multiple notes forms a composition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a48ade6",
      "metadata": {
        "id": "1a48ade6"
      },
      "outputs": [],
      "source": [
        "comp_minuet = make_composition(minuet_notes, minuet_amplitude, minuet_duration, minuet_onsets)\n",
        "comp_telemann = make_composition(telemann_notes, telemann_amplitude, telemann_duration, telemann_onsets)\n",
        "comp_naruto = make_composition(naruto_notes, naruto_amplitude, naruto_duration, naruto_onsets)\n",
        "comp_gurenge = make_composition(gurenge_notes, gurenge_amplitude, gurenge_duration, gurenge_onsets)\n",
        "comp_silhouette = make_composition(silhouette_notes, silhouette_amplitude, silhouette_duration, silhouette_onsets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd12f92",
      "metadata": {
        "id": "edd12f92"
      },
      "outputs": [],
      "source": [
        "comp_naruto = make_composition(naruto_notes, naruto_amplitude, naruto_duration, naruto_onsets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6060d888",
      "metadata": {
        "id": "6060d888"
      },
      "source": [
        "### Create Synthesizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffaef30d",
      "metadata": {
        "id": "ffaef30d"
      },
      "source": [
        "The synthesizer is a class with different functionalities, that needs to be created, giving the desired frequency of sampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36457637",
      "metadata": {
        "id": "36457637"
      },
      "outputs": [],
      "source": [
        "# silhouette synthesized audio will be used as a example\n",
        "# Create synthesizer\n",
        "my_synthesizer = synthesizer(fs_silhouette) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2375216b",
      "metadata": {
        "id": "2375216b"
      },
      "source": [
        "### Wavetables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6db9c15b",
      "metadata": {
        "id": "6db9c15b"
      },
      "source": [
        "Other functionality of the class is the generation of wavetables. Four options of wavetables are considered: </p>\n",
        "- Sin (only has one harmonic, which is the fundamental frequency. Therefore is quit boring to hear)\n",
        "- Sawtooth (It creates harmonics multiple integers of the fundamental frequency and decays as $ \\dfrac{1}{n}$)\n",
        "- Square (consists in all the odd harmonics and its amplitude decays as $ \\dfrac{1}{n}$)\n",
        "- Triangle (consists by some harmonics which amplitude that decays as $ \\dfrac{1}{n^2}$)\n",
        "\n",
        "The synthesizer works by looping through the composition and adding, to a final array of the synthesized audio signal, the signal of each note with the desired wavetable and envelope, at their correct position in time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "879bc5aa",
      "metadata": {
        "id": "879bc5aa"
      },
      "outputs": [],
      "source": [
        "wavetables = [np.sin, square, sawtooth, sawtooth]\n",
        "width = 1\n",
        "duty_cycle=0.5\n",
        "for wt in wavetables:\n",
        "    if wt == np.sin:\n",
        "        print(\"Sin Wavetable\")\n",
        "    elif wt == square:\n",
        "        print(\"Square Wavetable\")\n",
        "    elif wt == sawtooth and width == 1:\n",
        "        print(\"Sawtooth Wavetable\")\n",
        "    else:\n",
        "        print(\"Triangle Wavetable\")\n",
        "    # Generate sin wavetable\n",
        "    my_synthesizer.wavetable_generate(wt, width=width, dc=duty_cycle) \n",
        "    if wt == sawtooth:\n",
        "        width=0.5\n",
        "    # Create audio vector\n",
        "    synth_silhouette=my_synthesizer.synthesize(composition=comp_silhouette) \n",
        "    # Play the output signal\n",
        "    display(Audio(synth_silhouette, rate=fs_silhouette))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36c3e957",
      "metadata": {
        "id": "36c3e957"
      },
      "source": [
        "### Beat Change"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "730842ac",
      "metadata": {
        "id": "730842ac"
      },
      "source": [
        "In Music, the beat is the basic unit of time. Changing the beat will make the music slower or faster. 'shilhuette.wav' composition has originally 100 BPM, and a change to 90 BMP is done, making it sound slower."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e57d2c3",
      "metadata": {
        "id": "0e57d2c3"
      },
      "outputs": [],
      "source": [
        "# Generate square wavetable\n",
        "my_synthesizer.wavetable_generate(sawtooth, dc=0.5) \n",
        "\n",
        "# Define beat as 60\n",
        "comp_nbeat_silhouette=my_synthesizer.define_beat(composition=comp_silhouette, new_beat = 90, old_beat=silhouette_tempo)\n",
        "\n",
        "# Create audio vector\n",
        "synth_nbeat_silhouette=my_synthesizer.synthesize(comp_nbeat_silhouette) \n",
        "\n",
        "# Play the output signal\n",
        "display(Audio(synth_nbeat_silhouette, rate=fs_silhouette))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b2201ec",
      "metadata": {
        "id": "0b2201ec"
      },
      "outputs": [],
      "source": [
        "# Confirmation using librosa beat track\n",
        "new_tempo, _ = librosa.beat.beat_track(y=synth_nbeat_silhouette, sr=fs_naruto)\n",
        "print(\"original beat value: \", silhouette_tempo)\n",
        "print(\"new beat value: \", new_tempo)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "955d8119",
      "metadata": {
        "id": "955d8119"
      },
      "source": [
        "### Envelope Change"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2c595de",
      "metadata": {
        "id": "e2c595de"
      },
      "source": [
        "The ADSR envelope describes the evolution of amplitude of each note. Changing it will modify the timbre of the note."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59f669fd",
      "metadata": {
        "id": "59f669fd"
      },
      "outputs": [],
      "source": [
        "# Generate sin wavetable\n",
        "my_synthesizer.wavetable_generate(sawtooth, width=0.5) \n",
        "\n",
        "# Define envelope format\n",
        "my_synthesizer.define_adsr_envelope(attack=0.01, decay=0.4, sustain=0.01, release=0.2, height=1) \n",
        "\n",
        "# Create audio vector\n",
        "synth_adsr_silhouette = my_synthesizer.synthesize(comp_silhouette) \n",
        "\n",
        "print(\"Original signal\")\n",
        "plot_audio(synth_silhouette,spectrogram=False)\n",
        "display(Audio(synth_silhouette, rate=fs_naruto))\n",
        "print(\"Signal with envelope change\")\n",
        "plot_audio(synth_adsr_silhouette,spectrogram=False)\n",
        "# Play the output signal\n",
        "display(Audio(synth_adsr_silhouette, rate=fs_naruto))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "082c25b9",
      "metadata": {
        "id": "082c25b9"
      },
      "source": [
        "### Octave Change"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebc8085c",
      "metadata": {
        "id": "ebc8085c"
      },
      "source": [
        "Change the octave of the notes is multiplying their frequency by $2^n$, where n is the number of octaves we intend to change. If n is positive, the notes change to a higher octave and, if n is negative, they change to a lower octave."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23bb931f",
      "metadata": {
        "id": "23bb931f"
      },
      "outputs": [],
      "source": [
        "# Minus one octave Up\n",
        "comp_oct_silhouette = my_synthesizer.octave_change(comp_silhouette, change=-1)\n",
        "\n",
        "# Generate sin wavetable\n",
        "my_synthesizer.wavetable_generate(sawtooth, width=0.5) \n",
        "\n",
        "# Define envelope format\n",
        "my_synthesizer.define_adsr_envelope(attack=0.1, decay=0.2, sustain=0.8, release=0.4, height=1) \n",
        "\n",
        "# Create audio vector\n",
        "synth_delay_silhouette = my_synthesizer.synthesize(comp_oct_silhouette) \n",
        "\n",
        "# Plot the output signal\n",
        "plot_audio(synth_delay_silhouette,spectrogram=False)\n",
        "\n",
        "# Play the output signal\n",
        "display(Audio(synth_delay_silhouette, rate=fs_naruto))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9745ac7",
      "metadata": {
        "id": "e9745ac7"
      },
      "source": [
        "### Delay"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2129f84",
      "metadata": {
        "id": "f2129f84"
      },
      "source": [
        "A delay can be added to the start of the audio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f0f338",
      "metadata": {
        "id": "e9f0f338"
      },
      "outputs": [],
      "source": [
        "# Add delay of 2 second\n",
        "comp_delay_silhouette = my_synthesizer.delay_t(comp_silhouette,t_delay=2) \n",
        "\n",
        "# Define envelope format\n",
        "my_synthesizer.define_adsr_envelope(attack=0.1, decay=0.2, sustain=0.8, release=0.4, height=1) \n",
        "\n",
        "# Create audio vector\n",
        "synth_delay_silhouette = my_synthesizer.synthesize(comp_delay_silhouette) \n",
        "\n",
        "# Plot the output signal\n",
        "plot_audio(synth_delay_silhouette,spectrogram=False)\n",
        "\n",
        "# Play the output signal\n",
        "display(Audio(synth_delay_silhouette, rate=fs_naruto))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea596970",
      "metadata": {
        "id": "ea596970"
      },
      "source": [
        "### Piano Sound"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "723b3cf3",
      "metadata": {
        "id": "723b3cf3"
      },
      "source": [
        "It is also possible to recreate a synthesized piano version! Which is possible by getting the notes from previously recorded audios of a real piano wave of each note."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b1919ba",
      "metadata": {
        "id": "9b1919ba"
      },
      "outputs": [],
      "source": [
        "synth_piano_silhouette=my_synthesizer.piano(comp_silhouette, fs_silhouette)\n",
        "\n",
        "display(Audio(synth_piano_silhouette, rate=fs_silhouette))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HRGT6EI2MUNb",
      "metadata": {
        "id": "HRGT6EI2MUNb"
      },
      "source": [
        "## Code Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cGm9HIAsMUNb",
      "metadata": {
        "id": "cGm9HIAsMUNb"
      },
      "source": [
        "To test the implemented onset detectors and extractors of pitch, amplitude and duration, a composition was manually composed, having, thus, notes with well-known onset, pitch, amplitude and duration. The composition was previously synthesized in a simple sawtooth wave audio that is loaded here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sSfrBvZSMUNb",
      "metadata": {
        "id": "sSfrBvZSMUNb"
      },
      "outputs": [],
      "source": [
        "# Define composition of test (note, amplitude, duration, initial instant)\n",
        "comp_tminuet = (('G4', 1, 0.5,0), ('C4',0.5,0.25,0.5), ('D4', 0.6,0.25,0.75), ('E4', 0.7,0.25,1),('F4',0.8, 0.25,1.25), \n",
        "          ('G4',0.9,0.5,1.5), ('C4',1,0.5, 2),('C4', 1, 0.5 ,2.5),\n",
        "        ('A4',1,0.5,3), ('F4',0.5,0.25,3.5), ('G4', 0.6, 0.25,3.75), ('A4', 0.7,0.25, 4), ('B4', 0.8,0.25,4.25), \n",
        "          ('C5',0.9,0.5,4.5), ('C4',1,0.5,5),('C4',1,0.5,5.5))\n",
        "    \n",
        "\n",
        "# Load file with composition of test\n",
        "s_tminuet, fs_tminuet = librosa.load('projectPDS/recordings/tminuet.wav')\n",
        "\n",
        "# Display compostition of test\n",
        "print('Composition of test:')\n",
        "display(Audio(s_tminuet, rate=fs_tminuet))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4qOSRAH9607u",
      "metadata": {
        "id": "4qOSRAH9607u"
      },
      "source": [
        "### Onset Detection Test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yTjT4P2j6-7A",
      "metadata": {
        "id": "yTjT4P2j6-7A"
      },
      "source": [
        "The code test of the onset detection is performed by comparison of the onsets detected using the implemented algorithms and the true onsets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XH9S77kB7mav",
      "metadata": {
        "id": "XH9S77kB7mav"
      },
      "outputs": [],
      "source": [
        "# Save known onset locations in a list\n",
        "tminuet_true_onsets=[]\n",
        "for note in comp_tminuet:\n",
        "    tminuet_true_onsets.append(note[3])\n",
        "\n",
        "# MADMOM CNN Onset detector\n",
        "tminuet_onsets_CNN = onset_detection('projectPDS/recordings/tminuet.wav', CNNOnsetProcessor(),lim=0.25)\n",
        "\n",
        "# MADMOM RNN Onset detector\n",
        "tminuet_onsets_RNN = onset_detection('projectPDS/recordings/tminuet.wav', RNNOnsetProcessor(),lim=0.2)\n",
        "\n",
        "# Test\n",
        "np.testing.assert_almost_equal(tminuet_onsets_CNN, tminuet_true_onsets, decimal=2)\n",
        "np.testing.assert_almost_equal(tminuet_onsets_RNN, tminuet_true_onsets, decimal=2)\n",
        "print('Onset detection test completed successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BLoUEz2AMUNc",
      "metadata": {
        "id": "BLoUEz2AMUNc"
      },
      "source": [
        "### Pitch Extration Test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s_zpxc7UMUNd",
      "metadata": {
        "id": "s_zpxc7UMUNd"
      },
      "source": [
        "The code test of the pitch extraction is performed by comparison of the notes detected using the function get_notes(), which resorts to the function pitch() to find the frequency of each note, with the true notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qHETbMpGMUNd",
      "metadata": {
        "id": "qHETbMpGMUNd"
      },
      "outputs": [],
      "source": [
        "# Save true notes in a list\n",
        "tminuet_true_notes=[]\n",
        "for note in comp_tminuet:\n",
        "    tminuet_true_notes.append(note[0])\n",
        "\n",
        "# Extraction of notes from the audio \n",
        "tminuet_notes = get_notes(s_tminuet, fs_tminuet, tminuet_onsets_CNN)\n",
        "\n",
        "# Test\n",
        "np.testing.assert_array_equal(tminuet_notes, tminuet_true_notes)\n",
        "\n",
        "print('Pitch extraction test completed successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9hPcH7tzMUNd",
      "metadata": {
        "id": "9hPcH7tzMUNd"
      },
      "source": [
        "### Amplitude Extraction Test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W6rhzx0n0dgw",
      "metadata": {
        "id": "W6rhzx0n0dgw"
      },
      "source": [
        "The code test of the amplitude extraction is performed by comparison of the notes amplitude, which is found by computation of the maximum RMS value with unitary frame and hop sizes, with the true amplitudes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-hgcRkaFMUNd",
      "metadata": {
        "id": "-hgcRkaFMUNd"
      },
      "outputs": [],
      "source": [
        "# Save true notes amplitude in a list\n",
        "tminuet_amp = []\n",
        "for note in comp_tminuet:\n",
        "    tminuet_amp.append(note[1])\n",
        "\n",
        "# Extraction of amplitudes from the audio \n",
        "test_rms = get_amplitude(s_tminuet, fs_tminuet, tminuet_onsets_CNN, 1, 1, False)\n",
        "\n",
        "# Test\n",
        "np.testing.assert_almost_equal(tminuet_amp, test_rms, decimal=1)\n",
        "print('Amplitude extraction test completed successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "isCby84L35FV",
      "metadata": {
        "id": "isCby84L35FV"
      },
      "source": [
        "### Duration Extraction Test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aBhh3Abj5Nju",
      "metadata": {
        "id": "aBhh3Abj5Nju"
      },
      "source": [
        "The code test of the duration extraction is performed by comparison of the notes duration, which is found as the diference between onsets, with the true durations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qgsqjssw3rfM",
      "metadata": {
        "id": "qgsqjssw3rfM"
      },
      "outputs": [],
      "source": [
        "# Save true notes duration in a list\n",
        "tminuet_dur = []\n",
        "for note in comp_tminuet:\n",
        "    tminuet_dur.append(note[2])\n",
        "\n",
        "# Extraction of durations from the audio \n",
        "tminuet_duration = get_duration(s_tminuet, fs_tminuet, tminuet_onsets_CNN)\n",
        "\n",
        "# Test\n",
        "np.testing.assert_almost_equal(tminuet_dur, tminuet_duration, decimal=2)\n",
        "print('Duration extraction test completed successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ANvd2H_BQ8A",
      "metadata": {
        "id": "8ANvd2H_BQ8A"
      },
      "source": [
        "### Polyphony Test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PshQKlaJMUNe",
      "metadata": {
        "id": "PshQKlaJMUNe"
      },
      "source": [
        "In order to test the code functions developed to make the polyphonic synthesizer, a simple test composition was used. The test composition has 2 notes: A4, with amplitude 0.5 and played for 2 seconds, and C6, with amplitude 0.7 and played for 1 second in the meantime of A4. An audio of the composition is synthesized using a sin wavetable. An envelope with null attack, decay and release, and unitary sustain, is considered given that, for the test, it is important that the energy of the signal is constant during the reproduction of each note.\n",
        "\n",
        "When 2 notes are reproduced simultaneously, the energy of the signal is the sum of the energy of the signal of each note. Thus, the function get_amplitude(), with unitary frame and hop sizes, is used to find the maximum RMS value at the time each note is reproduced. Then, an assert check is used to verify if the obtained RMS value of the first note corresponds to its true amplitude and if the RMS value of the second note corresponds to the sum of the true amplitudes of the two notes, since, at that time, they are being reproduced at the same time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qzeg-YsxMUNe",
      "metadata": {
        "id": "qzeg-YsxMUNe"
      },
      "outputs": [],
      "source": [
        "comp_polyphonic = (\n",
        "    ('A4', 0.5, 2, 0), \n",
        "    ('C6',0.7, 1,0.5))\n",
        "\n",
        "onsets_polyphonic = [0, 0.5]\n",
        "\n",
        "# Save true notes amplitude in a list\n",
        "polyphonic_amp = []\n",
        "for note in comp_polyphonic:\n",
        "    polyphonic_amp.append(note[1])\n",
        "\n",
        "# ---Synthesize composition---\n",
        "# Create synthesizer\n",
        "fs=22050\n",
        "my_synthesizer = synthesizer(fs)\n",
        "\n",
        "# Generate sin wavetable\n",
        "my_synthesizer.wavetable_generate(np.sin) \n",
        "\n",
        "# Change envelope\n",
        "my_synthesizer.define_adsr_envelope(attack=0.0, decay=0, sustain=1, release=0, height=1) \n",
        "\n",
        "# Create audio vector\n",
        "synth_polyphonic = my_synthesizer.synthesize(comp_polyphonic) \n",
        "\n",
        "# Play the output signal\n",
        "display(Audio(synth_polyphonic, rate=22050))\n",
        "\n",
        "# Compute amplitude of detected notes to get the maximum RMS values of the signal\n",
        "rms_polyphonic = get_amplitude(synth_polyphonic, fs, onsets_polyphonic, 1, 1, False)\n",
        "\n",
        "# Test\n",
        "assert np.isclose(rms_polyphonic[0], polyphonic_amp[0], atol=0.05)\n",
        "assert np.isclose(rms_polyphonic[1], polyphonic_amp[0]+polyphonic_amp[1], atol=0.05)\n",
        "print('Polyphony test completed successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2a865da",
      "metadata": {
        "id": "d2a865da"
      },
      "source": [
        "## Some Interesiting results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e30ff09",
      "metadata": {
        "id": "5e30ff09"
      },
      "outputs": [],
      "source": [
        "# Create synthsizer \n",
        "fs = 48000\n",
        "interesting_synth= synthesizer(fs=48000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deac00cd",
      "metadata": {
        "id": "deac00cd"
      },
      "source": [
        "### Minuet different versions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4297210",
      "metadata": {
        "id": "f4297210"
      },
      "source": [
        "Original version of minuet is from viola and it is synthesized for two different timbres:\n",
        "- piano\n",
        "- sawtooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96a448f",
      "metadata": {
        "id": "d96a448f"
      },
      "outputs": [],
      "source": [
        "# synthesizer settings\n",
        "interesting_synth.wavetable_generate(sawtooth, width=0.8) \n",
        "interesting_synth.define_adsr_envelope(attack=0.1, decay=0.4, sustain=0.2, release=0.2, height=1) \n",
        "\n",
        "synth_minuet = interesting_synth.synthesize(comp_minuet)\n",
        "\n",
        "synth_piano_minuet = interesting_synth.piano(comp_minuet, fs_minuet)\n",
        "\n",
        "print(\"Original Viola version:\")\n",
        "display(Audio(s_minuet, rate=fs_minuet))\n",
        "print(\"Synthesized Piano version:\")\n",
        "display(Audio(synth_piano_minuet, rate= fs_minuet))\n",
        "print(\"Synthesized Sawtooth version:\")\n",
        "display(Audio(synth_minuet, rate = fs_minuet))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6158fbb",
      "metadata": {
        "id": "b6158fbb"
      },
      "source": [
        "From the results we can hear that it is not perfect due to fact that onset detection didnt show f-measure of one. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d0cd979",
      "metadata": {
        "id": "0d0cd979"
      },
      "source": [
        "### Simple boring version of telemann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fbfb4b5",
      "metadata": {
        "id": "2fbfb4b5"
      },
      "outputs": [],
      "source": [
        "interesting_synth.wavetable_generate(np.sin) \n",
        "interesting_synth.define_adsr_envelope(attack=0.1, decay=0.4, sustain=0.01, release=0.1, height=1) \n",
        "\n",
        "synth_boring_telemann = interesting_synth.synthesize(comp_telemann)\n",
        "\n",
        "print(\"Original Version:\")\n",
        "display(Audio(s_telemann, rate=fs_telemann))\n",
        "print(\"Boring Version:\")\n",
        "display(Audio(synth_boring_telemann, rate=fs_telemann))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74309cc0",
      "metadata": {
        "id": "74309cc0"
      },
      "source": [
        "The telemann audio is only synthesized with sin wavetable so, as expected, without harmonics the sound is not very interesting. However, contrasting with minuet audio, the onset detection is perfect for telemann which gives better results after synthesis. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93154ac6",
      "metadata": {
        "id": "93154ac6"
      },
      "source": [
        "### Gurenge lower tone plus it's delayed version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7eae72e",
      "metadata": {
        "id": "f7eae72e"
      },
      "outputs": [],
      "source": [
        "# Composition Change\n",
        "# lower one octave\n",
        "interesting_synth.wavetable_generate(sawtooth, width=0.5) \n",
        "interesting_synth.define_adsr_envelope(attack=0.01, decay=0.4, sustain=0.01, release=0.1, height=1) \n",
        "comp_oct_gurenge = interesting_synth.octave_change(comp_gurenge, change=-1)\n",
        "synth_adsr_gurenge = interesting_synth.synthesize(comp_oct_gurenge) \n",
        "# delay 0.1 seconds\n",
        "interesting_synth.wavetable_generate(sawtooth, width=1) \n",
        "interesting_synth.define_adsr_envelope(attack=0.2, decay=0.4, sustain=0.1, release=0.1, height=1) \n",
        "comp_delay_gurenge = interesting_synth.delay_t(comp_gurenge, t_delay=0.1) \n",
        "synth_delay_gurenge = interesting_synth.synthesize(comp_delay_gurenge)\n",
        "\n",
        "synth_final_gurenge = interesting_synth.add_two_signal(synth_delay_gurenge, synth_adsr_gurenge)\n",
        "print(\"Original Version\")\n",
        "display(Audio(s_gurenge, rate=fs_gurenge))\n",
        "print(\"Delayed version one octave lower\")\n",
        "display(Audio(synth_final_gurenge, rate=fs_gurenge))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a77a09d",
      "metadata": {
        "id": "9a77a09d"
      },
      "source": [
        "The gurenge audio is concatenated with a delayed version which can make some \"ECO\" effect, it is also lowered one octave to distinguish from the original one. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54f78cba",
      "metadata": {
        "id": "54f78cba"
      },
      "source": [
        "### Silhouette Polyphonic"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94761239",
      "metadata": {
        "id": "94761239"
      },
      "source": [
        "Below is combined silhouette audio and hand-composed secondary composition, resulting in a piano polyphonic audio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e056a78b",
      "metadata": {
        "id": "e056a78b"
      },
      "outputs": [],
      "source": [
        "# Making Secondary Composition\n",
        "Beat = 150 # Beat Value need be manually ajusted\n",
        "Quaver_duration = (60/Beat)/2 # each note is a quaver(half a beat)\n",
        "\n",
        "silhouette_sec_amplitude = 0.05 \n",
        "silhouette_sec_notes =('F#2', 'D2', 'F#2', 'A2', 'D3', 'A2', 'F#2','D2',\n",
        "                  'G2', 'D2', 'G2','B2', 'D3', 'B2', 'G2', 'D2',\n",
        "                  'A2', 'E2', 'A2', 'E3', 'A3', 'E3', 'A2', 'E2',\n",
        "                  'A#2', 'F#2', 'A#2', 'F#3', 'A#3', 'F#3', 'A#2', 'F#2',\n",
        "                  'B2','F#2', 'C3', 'F#3', 'B3', 'F#3', 'B2', 'F#2',\n",
        "                  'F#2', 'A2', 'D3', 'A3', 'D4', 'A3', 'D3', 'A2')\n",
        "\n",
        "comp_silhouette_sec=[]\n",
        "prev_note_start = silhouette_onsets[0]\n",
        "for note in silhouette_sec_notes:\n",
        "    features =[]\n",
        "    features.append(note) # note\n",
        "\n",
        "    features.append(silhouette_sec_amplitude) # amplitude\n",
        "    features.append(Quaver_duration) # duration\n",
        "    features.append(prev_note_start)\n",
        "\n",
        "    prev_note_start = prev_note_start+Quaver_duration\n",
        "    comp_silhouette_sec.append(features)\n",
        "\n",
        "# Synthesizing\n",
        "# Main Composition\n",
        "print(\"Silhouette main comp\")\n",
        "synth_silhouette = interesting_synth.piano(composition = comp_silhouette, fs=fs_silhouette)\n",
        "display(Audio(synth_silhouette, rate=fs_silhouette))\n",
        "\n",
        "# Secondary Composition\n",
        "print(\"Silhouette second comp\")\n",
        "synth_silhouette_sec=interesting_synth.piano(composition=comp_silhouette_sec, fs=fs_silhouette) \n",
        "display(Audio(synth_silhouette_sec, rate=fs_silhouette))\n",
        "\n",
        "# Complete Composition\n",
        "synth_silhouette_complete=interesting_synth.add_two_signal(synth_silhouette_sec, synth_silhouette)\n",
        "print(\"Silhouette complete\")\n",
        "display(Audio(synth_silhouette_complete, rate=fs_silhouette))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97986221",
      "metadata": {
        "id": "97986221"
      },
      "source": [
        "The polyphony makes the sound a lot richer as we can hear from the concatenation of those audio files. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2cb2088",
      "metadata": {
        "id": "f2cb2088"
      },
      "source": [
        "### Fast Piano version of Naruto with two octave lower"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ae6b62b",
      "metadata": {
        "id": "4ae6b62b"
      },
      "outputs": [],
      "source": [
        "#lower one octave\n",
        "comp_new_naruto = interesting_synth.octave_change(comp_naruto, change=-2)\n",
        "comp_new_naruto = interesting_synth.define_beat(comp_new_naruto, new_beat=240, old_beat=naruto_tempo)\n",
        "synth_new_naruto = interesting_synth.piano(composition=comp_new_naruto, fs=fs_naruto)\n",
        "\n",
        "print(\"Orignal Version:\")\n",
        "display(Audio(s_naruto, rate=fs_naruto))\n",
        "\n",
        "print(\"Fast synthesized piano version with 2 ocatave lower:\")\n",
        "display(Audio(synth_new_naruto, rate=fs_naruto))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01a9c072",
      "metadata": {
        "id": "01a9c072"
      },
      "source": [
        "Some composition sounds better with low frequency notes, which is the case of the naruto composition, it is synthesized with 240 BPM and two octaves lower."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dfd5279",
      "metadata": {
        "id": "6dfd5279"
      },
      "source": [
        "# References:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d453b762",
      "metadata": {
        "id": "d453b762"
      },
      "source": [
        "Audios:<br />\n",
        "https://www.youtube.com/watch?v=S8RZJ8GndBA <br/>\n",
        "https://www.youtube.com/watch?v=qGjFGaWJPi8 <br/>\n",
        "https://www.youtube.com/watch?v=qdvYO8HgbEQ <br/>\n",
        "https://www.youtube.com/watch?v=9mIUEN1GIRw \n",
        "\n",
        "Single Piano Notes Collection:<br />\n",
        "https://github.com/plemaster01/PythonPiano </p>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}